{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# A multi classes image classifier, based on convolutional neural network using Keras and Tensorflow. \n",
    "# A multi-label classifier (having one fully-connected layer at the end), with multi-classification (18 classes, in this instance).\n",
    "# Largely copied from the code https://gist.github.com/seixaslipe\n",
    "# This is based on these posts: https://medium.com/alex-attia-blog/the-simpsons-character-recognition-using-keras-d8e1796eae36\n",
    "# Data downloaded from Kaggle \n",
    "# Will emulate the image classification functionlities for Neuro Pathology images/slides (WSI-Whole Slide images)\n",
    "# Will implement/include data manipulating functionalities based on Girder (https://girder.readthedocs.io/en/latest/)\n",
    "# Has 6 convulsions, filtering start with 64, 128, 256 with flattening to 1024\n",
    "# Used Keras.ImageDataGenerator for Training/Validation data augmentation and the augmented images are flown from respective directory\n",
    "# Environment: A docker container having Keras, TensorFlow, Python-2 with GPU based execution\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "import datetime, time, os, sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib as plt\n",
    "plt.use('Agg')\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.figure\n",
    "import pickle \n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "import nvidia_smi as nvs\n",
    "import io\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nvidia-ml-py --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: 384.130\n",
      "Device 0: GeForce GTX 1050\n",
      "Found 19548 images belonging to 20 classes.\n",
      "Found 990 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "modelInfo = {}\n",
    "modelInfo['Device']  = {} ## Initialize an object to store info on the model and time info\n",
    "\n",
    "nvs.nvmlInit()\n",
    "\n",
    "driverVersion = nvs.nvmlSystemGetDriverVersion()\n",
    "print(\"Driver Version: {}\".format(driverVersion))\n",
    "modelInfo['Device']['driverVersion']  = driverVersion\n",
    "\n",
    "# e.g. will print:\n",
    "#   Driver Version: 352.00\n",
    "deviceCount = nvs.nvmlDeviceGetCount()\n",
    "deviceNames = []\n",
    "for i in range(deviceCount):\n",
    "    handle = nvs.nvmlDeviceGetHandleByIndex(i)\n",
    "    dvn = nvs.nvmlDeviceGetName(handle) # store the device name\n",
    "    print(\"Device {}: {}\".format(i,  dvn))\n",
    "    deviceNames.append(dvn)\n",
    "    # e.g. will print:\n",
    "    #  Device 0 : Tesla K40c\n",
    "nvs.nvmlShutdown()\n",
    "\n",
    "modelInfo['Device']['deviceNames']  = deviceNames\n",
    "\n",
    "\n",
    "### These parameters can be tuned and may affect classification results or accuracy\n",
    "img_width, img_height = 64, 64\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "modelInfo['batch_size'] = batch_size\n",
    "modelInfo['epochs'] = epochs\n",
    "modelInfo['img_width'] = 64\n",
    "modelInfo['img_height'] = 64\n",
    " \n",
    "\n",
    "### Define input dirs and output for results which contain the models as well as stats on the run\n",
    "train_data_dir = '/data/train' \n",
    "validation_data_dir = '/data/test' \n",
    "\n",
    "resultsDir =\"/app/results/\"\n",
    "if not os.path.isdir(resultsDir):\n",
    "    os.makedirs(resultsDir)\n",
    "\n",
    "nb_train_samples = 0\n",
    "\n",
    "for root, dirs, files in os.walk(train_data_dir):\n",
    "    nb_train_samples += len(files)\n",
    "\n",
    "nb_validation_samples = 0\n",
    "for root, dirs, files in os.walk(validation_data_dir):\n",
    "    nb_validation_samples += len(files)\n",
    "\n",
    "\n",
    "# Model definition\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255.0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Only rescaling for validation\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255.0)\n",
    "\n",
    "# Flows the data directly from the directory structure, resizing where needed\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "NumLabels = len(validation_generator.class_indices)\n",
    "\n",
    "'''\n",
    "6-conv layers - added on 06/21, Raj\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NumLabels, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Captures GPU usage\n",
    "#subprocess.Popen(\"timeout 120 nvidia-smi --query-gpu=utilization.gpu,utilization.memory --format=csv -l 1 | sed s/%//g > /app/results/GPU-stats.log\",shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nvidia-ml-py --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 106s 695ms/step - loss: 2.7127 - acc: 0.1663 - val_loss: 2.4388 - val_acc: 0.2846\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 98s 642ms/step - loss: 2.0380 - acc: 0.3806 - val_loss: 1.6881 - val_acc: 0.5011\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 97s 638ms/step - loss: 1.5223 - acc: 0.5455 - val_loss: 1.1285 - val_acc: 0.6417\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 97s 641ms/step - loss: 1.1848 - acc: 0.6444 - val_loss: 0.8320 - val_acc: 0.7411\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 97s 635ms/step - loss: 0.9951 - acc: 0.7040 - val_loss: 0.6905 - val_acc: 0.7969\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 95s 628ms/step - loss: 0.8337 - acc: 0.7523 - val_loss: 0.4887 - val_acc: 0.8549\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 99s 650ms/step - loss: 0.7487 - acc: 0.7778 - val_loss: 0.4724 - val_acc: 0.8717\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 98s 644ms/step - loss: 0.6563 - acc: 0.8070 - val_loss: 0.4193 - val_acc: 0.8705\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 94s 618ms/step - loss: 0.5911 - acc: 0.8269 - val_loss: 0.2976 - val_acc: 0.9096\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 96s 632ms/step - loss: 0.5595 - acc: 0.8348 - val_loss: 0.2966 - val_acc: 0.9129\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 99s 652ms/step - loss: 0.5008 - acc: 0.8544 - val_loss: 0.2881 - val_acc: 0.9163\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 105s 688ms/step - loss: 0.4816 - acc: 0.8563 - val_loss: 0.2470 - val_acc: 0.9330\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 102s 673ms/step - loss: 0.4520 - acc: 0.8655 - val_loss: 0.2403 - val_acc: 0.9275\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 99s 654ms/step - loss: 0.4293 - acc: 0.8779 - val_loss: 0.2134 - val_acc: 0.9375\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 99s 651ms/step - loss: 0.3983 - acc: 0.8812 - val_loss: 0.2327 - val_acc: 0.9308\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 103s 675ms/step - loss: 0.4032 - acc: 0.8817 - val_loss: 0.1817 - val_acc: 0.9487\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 104s 682ms/step - loss: 0.3751 - acc: 0.8907 - val_loss: 0.1641 - val_acc: 0.9498\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 100s 657ms/step - loss: 0.3412 - acc: 0.9001 - val_loss: 0.1704 - val_acc: 0.9431\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 103s 675ms/step - loss: 0.3636 - acc: 0.8945 - val_loss: 0.1480 - val_acc: 0.9554\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 101s 667ms/step - loss: 0.3357 - acc: 0.9000 - val_loss: 0.1425 - val_acc: 0.9598\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 99s 652ms/step - loss: 0.3364 - acc: 0.9025 - val_loss: 0.1646 - val_acc: 0.9464\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 98s 647ms/step - loss: 0.3226 - acc: 0.9064 - val_loss: 0.1442 - val_acc: 0.9576\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 98s 643ms/step - loss: 0.3167 - acc: 0.9081 - val_loss: 0.1085 - val_acc: 0.9676\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 99s 651ms/step - loss: 0.3139 - acc: 0.9086 - val_loss: 0.1338 - val_acc: 0.9632\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 97s 640ms/step - loss: 0.2895 - acc: 0.9158 - val_loss: 0.1093 - val_acc: 0.9676\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 99s 648ms/step - loss: 0.2879 - acc: 0.9167 - val_loss: 0.1263 - val_acc: 0.9598\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 98s 644ms/step - loss: 0.2693 - acc: 0.9216 - val_loss: 0.0998 - val_acc: 0.9688\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 100s 659ms/step - loss: 0.2876 - acc: 0.9165 - val_loss: 0.1111 - val_acc: 0.9699\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 99s 653ms/step - loss: 0.2636 - acc: 0.9250 - val_loss: 0.0982 - val_acc: 0.9643\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 102s 668ms/step - loss: 0.2550 - acc: 0.9239 - val_loss: 0.1029 - val_acc: 0.9699\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 98s 646ms/step - loss: 0.2636 - acc: 0.9249 - val_loss: 0.0878 - val_acc: 0.9732\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 100s 658ms/step - loss: 0.2474 - acc: 0.9302 - val_loss: 0.0892 - val_acc: 0.9743\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 99s 648ms/step - loss: 0.2461 - acc: 0.9270 - val_loss: 0.0968 - val_acc: 0.9721\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 99s 654ms/step - loss: 0.2618 - acc: 0.9263 - val_loss: 0.1398 - val_acc: 0.9565\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 102s 672ms/step - loss: 0.2453 - acc: 0.9281 - val_loss: 0.0873 - val_acc: 0.9721\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 103s 674ms/step - loss: 0.2471 - acc: 0.9298 - val_loss: 0.1044 - val_acc: 0.9721\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 101s 667ms/step - loss: 0.2380 - acc: 0.9315 - val_loss: 0.0957 - val_acc: 0.9676\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 98s 644ms/step - loss: 0.2351 - acc: 0.9322 - val_loss: 0.0929 - val_acc: 0.9732\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 102s 673ms/step - loss: 0.2253 - acc: 0.9337 - val_loss: 0.0844 - val_acc: 0.9788\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 104s 682ms/step - loss: 0.2396 - acc: 0.9310 - val_loss: 0.0802 - val_acc: 0.9788\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 103s 677ms/step - loss: 0.2187 - acc: 0.9355 - val_loss: 0.0812 - val_acc: 0.9754\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 100s 661ms/step - loss: 0.2178 - acc: 0.9362 - val_loss: 0.0705 - val_acc: 0.9855\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 104s 684ms/step - loss: 0.2257 - acc: 0.9347 - val_loss: 0.0925 - val_acc: 0.9732\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 102s 674ms/step - loss: 0.2263 - acc: 0.9347 - val_loss: 0.0692 - val_acc: 0.9810\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 99s 653ms/step - loss: 0.2153 - acc: 0.9373 - val_loss: 0.0489 - val_acc: 0.9866\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 106s 696ms/step - loss: 0.2188 - acc: 0.9363 - val_loss: 0.0736 - val_acc: 0.9754\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 104s 681ms/step - loss: 0.2115 - acc: 0.9384 - val_loss: 0.0644 - val_acc: 0.9810\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 102s 671ms/step - loss: 0.2157 - acc: 0.9383 - val_loss: 0.0883 - val_acc: 0.9710\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 104s 687ms/step - loss: 0.1956 - acc: 0.9414 - val_loss: 0.0774 - val_acc: 0.9788\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 104s 685ms/step - loss: 0.1984 - acc: 0.9440 - val_loss: 0.0591 - val_acc: 0.9833\n",
      "Finished running the basic model... trying to save results now..\n"
     ]
    }
   ],
   "source": [
    "# Timehistory callback to get epoch run times\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Model fitting and training run\n",
    "simpsonsModel = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "\n",
    "    callbacks=[time_callback])    \n",
    "\n",
    "\n",
    "print \"Finished running the basic model... trying to save results now..\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write the each epoch run time into a json file\n",
    "now = datetime.datetime.now()\n",
    "filetime = str(now.year)+str(now.month)+str(now.day)+'_'+str(now.hour)+str(now.minute)\n",
    "\n",
    "modelInfo['epochTimeInfo'] = time_callback.times\n",
    "\n",
    "\n",
    "## Write out the h5/model\n",
    "modelfilename=resultsDir+'Simpsonsmodel_'+filetime+'.h5'\n",
    "model.save(modelfilename)\n",
    "\n",
    "## This outputs the training and validation accuracy and loss functions for each epoch\n",
    "## This will be graphed as well using plotly ... you can use this data to look for overfitting\n",
    "## and/or when you can stop training your model because it stops improving\n",
    "modelInfo['historyData'] =  pd.DataFrame(simpsonsModel.history).to_dict(orient='records')\n",
    "\n",
    "###target_names maps the character names (or labels) to the index(integer) used in the output files\n",
    "modelInfo['target_names']  = validation_generator.class_indices\n",
    "\n",
    "modelInfo['labelname_to_index']  = validation_generator.class_indices\n",
    "modelInfo['index_to_labelname']  = {(v,k) for k,v in validation_generator.class_indices.iteritems() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = validation_generator.class_indices\n",
    "\n",
    "## Prediction for TRAIN data set\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "\n",
    "##Prediction for TEST data set\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "cls_rpt = classification_report(validation_generator.classes, y_pred, target_names=target_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "charles_montgomery_burns       0.08      0.08      0.08        48\n",
      "            ned_flanders       0.02      0.02      0.02        50\n",
      "           homer_simpson       0.08      0.08      0.08        50\n",
      "           lenny_leonard       0.04      0.04      0.04        48\n",
      "  abraham_grampa_simpson       0.04      0.04      0.04        50\n",
      "            mayor_quimby       0.06      0.06      0.06        49\n",
      "            chief_wiggum       0.06      0.06      0.06        50\n",
      "          edna_krabappel       0.04      0.04      0.04        50\n",
      "  apu_nahasapeemapetilon       0.02      0.02      0.02        50\n",
      "       principal_skinner       0.06      0.06      0.06        50\n",
      "           marge_simpson       0.04      0.04      0.04        50\n",
      "             moe_szyslak       0.10      0.10      0.10        50\n",
      "            nelson_muntz       0.04      0.04      0.04        50\n",
      "        krusty_the_clown       0.02      0.02      0.02        50\n",
      "           kent_brockman       0.08      0.08      0.08        49\n",
      "            bart_simpson       0.02      0.02      0.02        50\n",
      "            sideshow_bob       0.11      0.10      0.10        49\n",
      "          comic_book_guy       0.02      0.02      0.02        50\n",
      "            lisa_simpson       0.02      0.02      0.02        50\n",
      "     milhouse_van_houten       0.02      0.02      0.02        47\n",
      "\n",
      "             avg / total       0.05      0.05      0.05       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cls_rpt)  ### This is a 20 by 20 matrix\n",
    "\n",
    "## This looks cool, but we need to turn it into a table I guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turning into classification report into classification object\n",
    "avgresults = cls_rpt.strip().split('\\n')[-1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallResults={'label' : 'avg/total', 'precision': avgresults[3], 'recall':avgresults[4],'f1-score':avgresults[5], 'support':avgresults[6]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support  =  precision_recall_fscore_support(validation_generator.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInfo['classificationObject'] =  characterResultsArray =  {\n",
    "    'label': validation_generator.class_indices.keys(),\n",
    "    'precision': precision,\n",
    "    'recall':recall,\n",
    "    'fscore': fscore, 'support':support,\n",
    "    'overallResults':{'label' : 'avg/total', \n",
    "                      'precision': avgresults[3], \n",
    "                      'recall':avgresults[4],\n",
    "                      'f1-score':avgresults[5],\n",
    "                      'support':avgresults[6]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fscore': array([0.08247423, 0.01980198, 0.08080808, 0.04123711, 0.04      ,\n",
       "        0.0625    , 0.06060606, 0.03960396, 0.01980198, 0.06      ,\n",
       "        0.04040404, 0.1       , 0.04040404, 0.01980198, 0.08      ,\n",
       "        0.01904762, 0.10416667, 0.02061856, 0.02040816, 0.0212766 ]),\n",
       " 'label': ['charles_montgomery_burns',\n",
       "  'ned_flanders',\n",
       "  'homer_simpson',\n",
       "  'lenny_leonard',\n",
       "  'abraham_grampa_simpson',\n",
       "  'mayor_quimby',\n",
       "  'chief_wiggum',\n",
       "  'edna_krabappel',\n",
       "  'apu_nahasapeemapetilon',\n",
       "  'principal_skinner',\n",
       "  'marge_simpson',\n",
       "  'moe_szyslak',\n",
       "  'nelson_muntz',\n",
       "  'krusty_the_clown',\n",
       "  'kent_brockman',\n",
       "  'bart_simpson',\n",
       "  'sideshow_bob',\n",
       "  'comic_book_guy',\n",
       "  'lisa_simpson',\n",
       "  'milhouse_van_houten'],\n",
       " 'overallResults': {'f1-score': u'0.05',\n",
       "  'label': 'avg/total',\n",
       "  'precision': u'0.05',\n",
       "  'recall': u'0.05',\n",
       "  'support': u'990'},\n",
       " 'precision': array([0.08163265, 0.01960784, 0.08163265, 0.04081633, 0.04      ,\n",
       "        0.06382979, 0.06122449, 0.03921569, 0.01960784, 0.06      ,\n",
       "        0.04081633, 0.1       , 0.04081633, 0.01960784, 0.07843137,\n",
       "        0.01818182, 0.10638298, 0.0212766 , 0.02083333, 0.0212766 ]),\n",
       " 'recall': array([0.08333333, 0.02      , 0.08      , 0.04166667, 0.04      ,\n",
       "        0.06122449, 0.06      , 0.04      , 0.02      , 0.06      ,\n",
       "        0.04      , 0.1       , 0.04      , 0.02      , 0.08163265,\n",
       "        0.02      , 0.10204082, 0.02      , 0.02      , 0.0212766 ]),\n",
       " 'support': array([48, 50, 50, 48, 50, 49, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 49,\n",
       "        50, 50, 47])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInfo['classificationObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInfo['confusion_matrix'] = confusion_matrix(validation_generator.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 3, 1, 4, 2, 2, 1, 5, 4, 1, 1, 4, 2, 2, 2, 2, 1, 1, 4],\n",
       "       [2, 1, 2, 1, 3, 3, 1, 6, 2, 3, 2, 3, 2, 4, 1, 2, 2, 4, 4, 2],\n",
       "       [0, 4, 4, 4, 4, 4, 0, 2, 2, 4, 2, 0, 3, 1, 5, 1, 5, 3, 2, 0],\n",
       "       [5, 6, 2, 2, 4, 1, 3, 3, 1, 0, 2, 2, 2, 4, 1, 1, 2, 4, 1, 2],\n",
       "       [5, 2, 0, 4, 2, 2, 0, 4, 2, 3, 2, 2, 0, 2, 3, 6, 3, 1, 4, 3],\n",
       "       [2, 1, 1, 2, 2, 3, 3, 1, 1, 3, 5, 2, 3, 3, 5, 3, 1, 1, 4, 3],\n",
       "       [3, 4, 1, 3, 4, 3, 3, 2, 4, 1, 3, 2, 5, 3, 0, 2, 0, 2, 2, 3],\n",
       "       [3, 3, 2, 1, 0, 3, 3, 2, 4, 1, 3, 1, 2, 2, 2, 7, 3, 3, 2, 3],\n",
       "       [1, 2, 3, 1, 2, 2, 2, 4, 1, 1, 0, 1, 3, 4, 4, 2, 3, 5, 4, 5],\n",
       "       [1, 4, 4, 2, 2, 1, 4, 4, 5, 3, 2, 3, 2, 1, 2, 5, 2, 2, 0, 1],\n",
       "       [3, 2, 1, 3, 2, 1, 3, 1, 4, 2, 2, 1, 4, 4, 1, 4, 3, 2, 3, 4],\n",
       "       [1, 0, 2, 5, 1, 3, 1, 7, 2, 4, 3, 5, 3, 3, 1, 2, 2, 1, 2, 2],\n",
       "       [2, 3, 5, 4, 4, 2, 3, 0, 2, 2, 5, 2, 2, 4, 2, 5, 2, 0, 1, 0],\n",
       "       [3, 2, 2, 3, 3, 2, 0, 2, 4, 2, 3, 9, 2, 1, 1, 3, 0, 3, 2, 3],\n",
       "       [1, 2, 3, 3, 2, 3, 4, 3, 2, 2, 1, 2, 3, 1, 4, 3, 4, 3, 1, 2],\n",
       "       [5, 2, 3, 3, 2, 3, 2, 2, 3, 3, 1, 2, 1, 3, 4, 1, 1, 2, 4, 3],\n",
       "       [4, 2, 4, 2, 5, 1, 4, 1, 1, 1, 1, 1, 1, 4, 3, 0, 5, 2, 7, 0],\n",
       "       [1, 7, 2, 4, 2, 2, 6, 2, 2, 3, 1, 4, 2, 2, 1, 1, 2, 1, 2, 3],\n",
       "       [2, 1, 2, 0, 0, 3, 2, 3, 3, 3, 7, 2, 0, 2, 6, 2, 4, 4, 1, 3],\n",
       "       [1, 1, 3, 1, 2, 3, 3, 1, 1, 5, 3, 5, 5, 1, 3, 3, 1, 3, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInfo['confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-44a298889d69>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-44a298889d69>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    for image in glob(train/*):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "###   filename --- CLASS\n",
    "\n",
    "\n",
    "### LAST BUT NOT LEAST --- \n",
    "\n",
    "\n",
    "\n",
    "# MAKE IT A PARAMETER OUTPUT MODELPREDICTIOJ FOR TRAIN AND TEST OR JUST TEST  \n",
    "\n",
    "for image in glob(train/*):\n",
    "    I WANT\n",
    "    \n",
    "    ['filename': \"somename\", 'actualImageLabel': asIndex, 'modelPrection': X ]\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
