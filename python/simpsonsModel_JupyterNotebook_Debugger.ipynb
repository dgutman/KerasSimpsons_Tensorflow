{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# A multi classes image classifier, based on convolutional neural network using Keras and Tensorflow. \n",
    "# A multi-label classifier (having one fully-connected layer at the end), with multi-classification (18 classes, in this instance).\n",
    "# Largely copied from the code https://gist.github.com/seixaslipe\n",
    "# This is based on these posts: https://medium.com/alex-attia-blog/the-simpsons-character-recognition-using-keras-d8e1796eae36\n",
    "# Data downloaded from Kaggle \n",
    "# Will emulate the image classification functionlities for Neuro Pathology images/slides (WSI-Whole Slide images)\n",
    "# Will implement/include data manipulating functionalities based on Girder (https://girder.readthedocs.io/en/latest/)\n",
    "# Has 6 convulsions, filtering start with 64, 128, 256 with flattening to 1024\n",
    "# Used Keras.ImageDataGenerator for Training/Validation data augmentation and the augmented images are flown from respective directory\n",
    "# Environment: A docker container having Keras, TensorFlow, Python-2 with GPU based execution\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "import datetime, time, os, sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib as plt\n",
    "plt.use('Agg')\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.figure\n",
    "import pickle \n",
    "#from pickle import load\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "import nvidia_smi as nvs\n",
    "import io\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "try:\n",
    "    to_unicode = unicode\n",
    "except NameError:\n",
    "    to_unicode = str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: 384.130\n",
      "Device 0: GeForce GTX 1050\n",
      "Found 19548 images belonging to 20 classes.\n",
      "Found 990 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelInfo = {}\n",
    "modelInfo['Device']  = {} ## Initialize an object to store info on the model and time info\n",
    "\n",
    "nvs.nvmlInit()\n",
    "\n",
    "driverVersion = nvs.nvmlSystemGetDriverVersion()\n",
    "print(\"Driver Version: {}\".format(driverVersion))\n",
    "modelInfo['Device']['driverVersion']  = driverVersion\n",
    "\n",
    "# e.g. will print:\n",
    "#   Driver Version: 352.00\n",
    "deviceCount = nvs.nvmlDeviceGetCount()\n",
    "deviceNames = []\n",
    "for i in range(deviceCount):\n",
    "    handle = nvs.nvmlDeviceGetHandleByIndex(i)\n",
    "    dvn = nvs.nvmlDeviceGetName(handle) # store the device name\n",
    "    print(\"Device {}: {}\".format(i,  dvn))\n",
    "    deviceNames.append(dvn)\n",
    "    # e.g. will print:\n",
    "    #  Device 0 : Tesla K40c\n",
    "nvs.nvmlShutdown()\n",
    "\n",
    "modelInfo['Device']['deviceNames']  = deviceNames\n",
    "\n",
    "\n",
    "### These parameters can be tuned and may affect classification results or accuracy\n",
    "img_width, img_height = 64, 64\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "modelInfo['batch_size'] = batch_size\n",
    "modelInfo['epochs'] = epochs\n",
    "modelInfo['img_width'] = 64\n",
    "modelInfo['img_height'] = 64\n",
    " \n",
    "\n",
    "### Define input dirs and output for results which contain the models as well as stats on the run\n",
    "train_data_dir = '/data/train' \n",
    "validation_data_dir = '/data/test' \n",
    "\n",
    "resultsDir =\"/app/results/\"\n",
    "if not os.path.isdir(resultsDir):\n",
    "    os.makedirs(resultsDir)\n",
    "\n",
    "nb_train_samples = 0\n",
    "\n",
    "for root, dirs, files in os.walk(train_data_dir):\n",
    "    nb_train_samples += len(files)\n",
    "\n",
    "nb_validation_samples = 0\n",
    "for root, dirs, files in os.walk(validation_data_dir):\n",
    "    nb_validation_samples += len(files)\n",
    "\n",
    "\n",
    "# Model definition\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255.0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Only rescaling for validation\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255.0)\n",
    "\n",
    "# Flows the data directly from the directory structure, resizing where needed\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "NumLabels = len(validation_generator.class_indices)\n",
    "\n",
    "'''\n",
    "6-conv layers - added on 06/21, Raj\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NumLabels, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Captures GPU usage\n",
    "#subprocess.Popen(\"timeout 120 nvidia-smi --query-gpu=utilization.gpu,utilization.memory --format=csv -l 1 | sed s/%//g > /app/results/GPU-stats.log\",shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "152/152 [==============================] - 96s 632ms/step - loss: 2.7091 - acc: 0.1664 - val_loss: 2.4641 - val_acc: 0.2522\n",
      "Finished running the basic model... trying to save results now..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Timehistory callback to get epoch run times\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "\n",
    "# Model fitting and training run\n",
    "simpsonsModel = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "\n",
    "    callbacks=[time_callback])    \n",
    "\n",
    "\n",
    "print \"Finished running the basic model... trying to save results now..\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write the each epoch run time into a json file\n",
    "now = datetime.datetime.now()\n",
    "filetime = str(now.year)+str(now.month)+str(now.day)+'_'+str(now.hour)+str(now.minute)\n",
    "\n",
    "modelInfo['epochTimeInfo'] = time_callback.times\n",
    "\n",
    "\n",
    "## Write out the h5/model\n",
    "modelfilename=resultsDir+'Simpsonsmodel_'+filetime+'.h5'\n",
    "model.save(modelfilename)\n",
    "\n",
    "## This outputs the training and validation accuracy and loss functions for each epoch\n",
    "## This will be graphed as well using plotly ... you can use this data to look for overfitting\n",
    "## and/or when you can stop training your model because it stops improving\n",
    "modelInfo['historyData'] =  pd.DataFrame(simpsonsModel.history).to_dict(orient='records')\n",
    "\n",
    "###target_names maps the character names (or labels) to the index(integer) used in the output files\n",
    "modelInfo['target_names']  = validation_generator.class_indices\n",
    "\n",
    "modelInfo['labelname_to_index']  = validation_generator.class_indices\n",
    "modelInfo['index_to_labelname']  = {(v,k) for k,v in validation_generator.class_indices.iteritems() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "target_names = validation_generator.class_indices\n",
    "\n",
    "## Prediction for TRAIN data set\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "\n",
    "##Prediction for TEST data set\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "cls_rpt = classification_report(validation_generator.classes, y_pred, target_names=target_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "charles_montgomery_burns       0.00      0.00      0.00        48\n",
      "            ned_flanders       0.00      0.00      0.00        50\n",
      "           homer_simpson       0.06      0.06      0.06        50\n",
      "           lenny_leonard       0.00      0.00      0.00        48\n",
      "  abraham_grampa_simpson       0.08      0.28      0.13        50\n",
      "            mayor_quimby       0.00      0.00      0.00        49\n",
      "            chief_wiggum       0.00      0.00      0.00        50\n",
      "          edna_krabappel       0.03      0.10      0.04        50\n",
      "  apu_nahasapeemapetilon       0.00      0.00      0.00        50\n",
      "       principal_skinner       0.06      0.20      0.09        50\n",
      "           marge_simpson       0.00      0.00      0.00        50\n",
      "             moe_szyslak       0.00      0.00      0.00        50\n",
      "            nelson_muntz       0.06      0.10      0.07        50\n",
      "        krusty_the_clown       0.00      0.00      0.00        50\n",
      "           kent_brockman       0.20      0.04      0.07        49\n",
      "            bart_simpson       0.15      0.04      0.06        50\n",
      "            sideshow_bob       0.02      0.06      0.03        49\n",
      "          comic_book_guy       0.00      0.00      0.00        50\n",
      "            lisa_simpson       0.00      0.00      0.00        50\n",
      "     milhouse_van_houten       0.07      0.04      0.05        47\n",
      "\n",
      "             avg / total       0.04      0.05      0.03       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cls_rpt)  ### This is a 20 by 20 matrix\n",
    "\n",
    "## This looks cool, but we need to turn it into a table I guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The classification report needs to .. not be a report.. we need classification data..\n",
    "\n",
    "precision recall f1-score  support\n",
    "\n",
    "classificationObject =  { 'characterResultsArray': [ 'label': 'homer','precision': #, recall, #, f1-score: # ],\n",
    "                          'overallResults':  [ 'label' : 'avg/total', 'precision': 0.04, recall: 0.05]                         \n",
    "                                                ] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix.shape\n",
    "\n",
    "modelInfo['confusion_matrix'] = cnf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  3,  1, 11,  1,  0, 11,  0,  5,  0,  0,  4,  0,  0,  0,\n",
       "         7,  0,  3,  2],\n",
       "       [ 1,  0,  1,  3,  6,  0,  0, 10,  0, 16,  0,  0,  3,  0,  0,  0,\n",
       "         6,  0,  4,  0],\n",
       "       [ 2,  0,  3,  1,  6,  1,  0,  8,  0, 10,  0,  0,  3,  0,  0,  2,\n",
       "         9,  0,  2,  3],\n",
       "       [ 1,  0,  3,  0,  6,  1,  0, 13,  0, 11,  0,  0,  3,  0,  0,  1,\n",
       "         8,  0,  1,  0],\n",
       "       [ 3,  0,  3,  1, 14,  0,  0,  3,  0,  6,  0,  0,  7,  0,  0,  1,\n",
       "         8,  0,  1,  3],\n",
       "       [ 0,  0,  2,  0,  6,  0,  0, 11,  0,  5,  0,  0,  5,  0,  2,  0,\n",
       "        12,  0,  5,  1],\n",
       "       [ 1,  0,  2,  1, 10,  1,  0,  6,  0, 11,  0,  0,  3,  0,  0,  0,\n",
       "         8,  0,  6,  1],\n",
       "       [ 1,  0,  2,  0, 10,  0,  0,  5,  0, 12,  0,  0,  3,  0,  0,  0,\n",
       "        11,  0,  5,  1],\n",
       "       [ 0,  0,  3,  2,  8,  0,  0,  7,  0,  9,  0,  0,  5,  0,  0,  1,\n",
       "        10,  0,  4,  1],\n",
       "       [ 2,  0,  4,  0,  5,  0,  0,  8,  0, 10,  0,  0,  5,  0,  1,  0,\n",
       "         7,  0,  6,  2],\n",
       "       [ 1,  0,  4,  3, 10,  0,  0,  9,  0,  5,  0,  0,  3,  0,  2,  0,\n",
       "         7,  0,  3,  3],\n",
       "       [ 1,  0,  2,  2,  8,  0,  0,  8,  0,  9,  0,  0,  4,  0,  1,  1,\n",
       "         5,  0,  8,  1],\n",
       "       [ 1,  0,  2,  0, 10,  2,  0,  9,  0, 11,  0,  0,  5,  0,  0,  0,\n",
       "         5,  0,  5,  0],\n",
       "       [ 0,  0,  2,  2,  6,  1,  0,  5,  0, 10,  0,  0,  7,  0,  1,  2,\n",
       "         9,  0,  4,  1],\n",
       "       [ 2,  0,  2,  3, 10,  0,  0,  8,  0,  9,  0,  1,  4,  0,  2,  0,\n",
       "         3,  0,  3,  2],\n",
       "       [ 0,  0,  1,  0,  8,  0,  0, 13,  0, 11,  0,  0,  1,  0,  0,  2,\n",
       "        11,  0,  1,  2],\n",
       "       [ 1,  0,  3,  0, 10,  0,  0, 12,  0,  5,  0,  0,  9,  0,  0,  0,\n",
       "         3,  0,  5,  1],\n",
       "       [ 1,  0,  2,  0,  8,  1,  0, 11,  0, 10,  0,  0,  4,  0,  0,  0,\n",
       "         9,  0,  3,  1],\n",
       "       [ 1,  0,  2,  1, 11,  1,  0, 13,  0,  4,  0,  1,  5,  0,  0,  2,\n",
       "         7,  0,  0,  2],\n",
       "       [ 1,  0,  6,  2,  7,  0,  0,  9,  0,  6,  0,  0,  3,  0,  1,  1,\n",
       "         5,  0,  4,  2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInfo['confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###   filename --- CLASS\n",
    "\n",
    "\n",
    "### LAST BUT NOT LEAST --- \n",
    "\n",
    "\n",
    "\n",
    "# MAKE IT A PARAMETER OUTPUT MODELPREDICTIOJ FOR TRAIN AND TEST OR JUST TEST  \n",
    "\n",
    "for image in glob(train/*):\n",
    "    I WANT\n",
    "    \n",
    "    ['filename': \"somename\", 'actualImageLabel': asIndex, 'modelPrection': X ]\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#pandas.DataFrame(simpsonsModel.history).to_json(\"/data/trainingdata/simpsons_history_0629.json\")\n",
    "\n",
    "\n",
    "# saving Confusion Matrix and Classification Report to a text file for human vision\n",
    "\n",
    "\n",
    "\n",
    "# Serialize confusion matrix and prediction/probabilities matrix stores in json file\n",
    "\n",
    "modelInfo['confusionMatrix']   =  pd.DataFrame(cnf_matrix).to_dict(orient='records')\n",
    "modelInfo['prediction_report'] =  pd.DataFrame(y_pred).to_dict(orient='records')\n",
    "\n",
    "#modelInfo['classification_report'] = \n",
    "\n",
    "\n",
    "# df=pd.DataFrame(cnf_matrix)\n",
    "# df.to_json(rptjson, orient='records', lines=True)\n",
    "\n",
    "# sysoptfile = 'classificationSystemEnvironment_'+filetime+'.txt'\n",
    "# import subprocess\n",
    "# sysopt = (subprocess.check_output(\"lscpu\", shell=True).strip()).decode()\n",
    "# with open(sysoptfile,\"a+\") as f:\n",
    "#     for line in sysopt:\n",
    "#         f.write(line)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# saving Confusion Matrix and Classification Report to a file\n",
    "target_names = validation_generator.class_indices\n",
    "optfile = resultsDir+ 'SimpsonsModeoutput_'+filetime+'.txt'\n",
    "file = open(optfile, \"a+\")\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "ptropt= 'Confusion Matrix' \n",
    "print >> file, ptropt\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "print >>file, cnf_matrix\n",
    "\n",
    "\n",
    "ptropt = 'Classification Report'\n",
    "print >> file, ptropt\n",
    "cls_rpt = classification_report(validation_generator.classes, y_pred, target_names=target_names) \n",
    "print >> file, cls_rpt\n",
    "file.close()                                         \n",
    "\n",
    "\n",
    "\n",
    "resultSummaryFile = resultsDir + filetime + \".GutmansTextFile.json\"\n",
    "\n",
    "\n",
    "#Confusion Matrix is shown on a Plot\n",
    "pyplot.figure(figsize=(8,8))\n",
    "cnf_matrix =confusion_matrix(validation_generator.classes, y_pred)\n",
    "#classes = list(chardict.values())\n",
    "classes = list(target_names)\n",
    "pyplot.imshow(cnf_matrix, interpolation='nearest')\n",
    "pyplot.colorbar()\n",
    "tick_marks = np.arange(len(classes))  \n",
    "_ = pyplot.xticks(tick_marks, classes, rotation=90)\n",
    "_ = pyplot.yticks(tick_marks, classes)\n",
    "plotopt= resultsDir + 'SimpsonsModelImage_'+filetime+'.png'\n",
    "pyplot.savefig(plotopt)\n",
    "\n",
    "\n",
    "#To plot GPU usage\n",
    "# gpu = pd.read_csv(\"/app/results/GPU-stats.log\")   # make sure that 120 seconds have expired before running this cell\n",
    "# gpuplt=gpu.plot()\n",
    "# gpuplt=pyplot.show()\n",
    "# gpuplt='/app/results/SimsonsGPUImage_'+filetime+'.png'\n",
    "# pyplot.savefig(gpuplt) \n",
    "\n",
    "\n",
    "\n",
    "# saving Confusion Matrix and Classification Report to a file\n",
    "target_names = validation_generator.class_indices\n",
    "optfile = 'SimsonsModeloutput_'+filetime+'.txt'\n",
    "file = open(optfile, \"a+\")\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "ptropt= 'Confusion Matrix' \n",
    "print >> file, ptropt\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "print >>file, cnf_matrix\n",
    "\n",
    "# Serialize confusion matrix and stores in json file\n",
    "cmfile= resultsDir + 'SimpsonsModelConfusionMatrix_'+filetime+'.json' \n",
    "with io.open(cmfile, 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(cnf_matrix.tolist(),\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))\n",
    "\n",
    "\n",
    "\n",
    "modelInfo['confusionMatrixV1'] =  cnf_matrix.tolist()\n",
    "\n",
    "ptropt = 'Classification Report'\n",
    "print >> file, ptropt\n",
    "cls_rpt = classification_report(validation_generator.classes, y_pred, target_names=target_names) \n",
    "print >> file, cls_rpt\n",
    "rptjson= resultsDir + 'SimpsonsModelClassificationReport_'+filetime+'.json' \n",
    "with io.open(rptjson, 'w', encoding='utf8') as outfile:\n",
    "    str_ = json.dumps(cnf_matrix.tolist(),\n",
    "                      indent=4, sort_keys=True,\n",
    "                      separators=(',', ':'), ensure_ascii=False)\n",
    "    outfile.write(to_unicode(str_))\n",
    "file.close()                                         \n",
    "\n",
    "# sysoptfile = resultsDir + 'SimpsonsSystemEnvironment_'+filetime+'.txt'\n",
    "# import subprocess\n",
    "# sysopt = (subprocess.check_output(\"lscpu\", shell=True).strip()).decode()\n",
    "# with open(sysoptfile,\"a+\") as f:\n",
    "#     for line in sysopt:\n",
    "#         f.write(line)\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# LOCAL_DEVICES = device_lib.list_local_devices()\n",
    "\n",
    "# modelInfo['LOCAL_DEVICES'] = LOCAL_DEVICES\n",
    "\n",
    "\n",
    "\n",
    "with open(resultSummaryFile ,\"w\")  as fp:\n",
    "    json.dump(modelInfo,fp,indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
